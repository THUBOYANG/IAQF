{"cells":[{"metadata":{"trusted":true,"_uuid":"f852c262092b57410fa27ceddb27a1a988c659dc"},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout,Activation\nfrom pyhht.emd import EMD\n\nhigh_freq_predict = []\nlow_freq_predict = []\n\ndataset_train = pd.read_csv('../input/data_train_2.csv')# 5264\ndataset_test = pd.read_csv('../input/data_test_2.csv') #474\ndata_no_standard_train = pd.read_csv('../input/train_set_nostandard_2.csv') #5274\ndata_no_standard_test = pd.read_csv('../input/test_set_nostandard_2.csv') #474\n\n\nwhile len(dataset_train) < 5364:\n#EMD\n    data = pd.DataFrame(data_no_standard_train['predict'],index = data_no_standard_train['date'],columns=['predict'])\n    decomposer = EMD(data['predict'])               \n    imfs = decomposer.decompose()\n    low_freq = np.sum(imfs[3:],axis=0)\n#     arr = np.vstack((imfs,data['predict']))\n#     dataframe = pd.DataFrame(arr.T)\n#     dataframe.to_csv('imf.csv',index=None,columns=None)\n    high_freq = np.array(data['predict']-low_freq)\n    dataset_train.loc[:,'high_freq'] = high_freq[10:]\n    high_freq_predict.append(high_freq[-1])\n\n#标准化\n    training_set = dataset_train.iloc[:, 1:].values\n    \n    sc_x = MinMaxScaler(feature_range = (0, 1))\n#     sc_y_high_freq = MinMaxScaler(feature_range = (0, 1))\n    sc_y_low_freq = MinMaxScaler(feature_range = (0, 1))\n    \n    features = ['T10Y3M','curvature','BAMLCC0A1AAATRIV','DPRIME','VIXCLS','DJIA','SP500','twexb','twexm','twexo','DCPF3M','DCPN3M','DFF','NASDAQCOM','DTWEXB','TEDRATE','USD3MTD156N','USEPUINDXD','WILL5000INDFC','WILLRESIND','volatility10d','ma3d','ma10d']\n    training_set_scaled_x = sc_x.fit_transform(dataset_train.loc[:,features])\n    \n#     training_set_scaled_y_high_freq = sc_y_high_freq.fit_transform(training_set[:,[-4]])\n    training_set_scaled_y_low_freq = sc_y_low_freq.fit_transform(low_freq[10:].reshape(-1,1))\n    \n#     training_set_scaled_high_freq = np.hstack((training_set_scaled_x,training_set_scaled_y_high_freq))\n    training_set_scaled_low_freq = np.hstack((training_set_scaled_x,training_set_scaled_y_low_freq))\n    \n#     y_train_high_freq = training_set_scaled_high_freq[:,[-1]]\n    X_train, y_train_low_freq = training_set_scaled_x, training_set_scaled_low_freq[:,[-1]]\n    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n\n#训练模型，提取高频信息\n#     u1=100\n#     d1=0.3\n#     num_stack_layers1 = 3\n\n#     regressor1 = Sequential()\n\n#     regressor1.add(LSTM(units = u1, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n#     regressor1.add(Dropout(d1))\n#     for i in range(num_stack_layers1-2):\n#         regressor1.add(LSTM(units = u1, return_sequences = True))\n#         regressor1.add(Dropout(d1))\n#     regressor1.add(LSTM(units = u1))\n#     regressor1.add(Dropout(d1))\n\n#     regressor1.add(Dense(units = 1))\n\n#     regressor1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n#     regressor1.fit(X_train, y_train_high_freq, epochs = 5, batch_size = 32)\n\n#训练模型，提取低频信息\n    u2=100\n    d2=0.3\n    num_stack_layers2 = 3\n\n    regressor2 = Sequential()\n\n    regressor2.add(LSTM(units = u2, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n    regressor2.add(Dropout(d2))\n    for i in range(num_stack_layers2-2):\n        regressor2.add(LSTM(units = u2, return_sequences = True))\n        regressor2.add(Dropout(d2))\n    regressor2.add(LSTM(units = u2))\n    regressor2.add(Dropout(d2))\n\n    regressor2.add(Dense(units = 1))\n\n    regressor2.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n    regressor2.fit(X_train, y_train_low_freq, epochs = 10, batch_size = 32)\n\n#样本外预测高频&低频\n    test_set = dataset_test.iloc[:,1:].values\n    X_test = np.array(dataset_test.loc[0,features]).reshape(1,-1)\n\n    X_test_scaled = sc_x.transform(X_test)\n\n    X_test_scaled = np.reshape(X_test_scaled, (X_test_scaled.shape[0],X_test_scaled.shape[1],1))\n\n#     y_predict_scaled_high_freq = regressor1.predict(X_test_scaled)\n    y_predict_scaled_low_freq = regressor2.predict(X_test_scaled)\n    \n#     y_predict_high_freq = sc_y_high_freq.inverse_transform(y_predict_scaled_high_freq)\n    y_predict_low_freq = sc_y_low_freq.inverse_transform(y_predict_scaled_low_freq)\n    \n#     high_freq_predict.append(y_predict_high_freq[0][0])\n    low_freq_predict.append(y_predict_low_freq[0][0])\n\n#更新数据\n    dataset_train.loc[len(dataset_train)] = dataset_test.loc[0]\n    \n    dataset_test = dataset_test.drop([0]).reset_index(drop = True)\n    \n    data_no_standard_train.loc[len(data_no_standard_train)] = data_no_standard_test.loc[0]\n    \n    data_no_standard_test = data_no_standard_test.drop([0]).reset_index(drop = True)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9cb58514846d3e42a2b55d98d0a41ee73734d316"},"cell_type":"code","source":"predict = pd.DataFrame(np.hstack((np.array(high_freq_predict).reshape(-1,1),np.array(low_freq_predict).reshape(-1,1))),columns=['high_freq','low_freq'])\npredict.to_csv('predict_2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a4af19bea2f58ff093cea2e304b3555c07f2d06c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}